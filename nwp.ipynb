{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prasanna-03/-LGMVIP--DataScience/blob/main/nwp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "85biWn0RL6FO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "JtUJ0O0fNY7M",
        "outputId": "a6d3c183-49cd-4028-ee15-91d616557414"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-27e280f2-4c81-4732-848a-b0415dbc7d45\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-27e280f2-4c81-4732-848a-b0415dbc7d45\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1661-0.txt to 1661-0 (1).txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "om6-UO3ONyYp",
        "outputId": "19b0c6e9-e6ae-4ba6-9b71-b3cc2c083305"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.net Title: The Adventures of Sherlock Holmes Author: Arthur Conan Doyle Release Date: November 29, 2002 [EBook #1661] Last Updated: May 20, 2019 Language: English Character set en\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "file = open(\"1661-0.txt\", \"r\", encoding = \"utf8\")\n",
        "lines =[]\n",
        "for i in file:\n",
        "\tlines.append(i)\n",
        "data = \"\"\n",
        "for i in lines:\n",
        "\tdata = ' '.join(lines)\n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('\"', '').replace('\"', '')\n",
        "data = data.split()\n",
        "data = ' '.join(data)\n",
        "data[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1oi169mPwnZ",
        "outputId": "f0cfffa6-a7fa-4831-f152-7af8e0208f89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "578728"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-e-C5qYP8Z9",
        "outputId": "5cd8f16b-384e-4f14-d002-7d874f3f16f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[145, 4789, 1, 1020, 4, 128, 34, 45, 611, 2235, 2236, 30, 1021, 15, 23]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "sequence_data[:15]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-99QCMUwQmD_",
        "outputId": "481f1927-5a22-4d39-9808-536b084722b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111252"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(sequence_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVOyOtQKQ1dv",
        "outputId": "edb18c90-b74c-4c27-e6c0-3986f1508efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8931\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMwuRo8_PhbO",
        "outputId": "fc69f495-0c26-43c0-b867-91264747049a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of sequences are:  111249\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 145, 4789,    1, 1020],\n",
              "       [4789,    1, 1020,    4],\n",
              "       [   1, 1020,    4,  128],\n",
              "       [1020,    4,  128,   34],\n",
              "       [   4,  128,   34,   45],\n",
              "       [ 128,   34,   45,  611],\n",
              "       [  34,   45,  611, 2235],\n",
              "       [  45,  611, 2235, 2236],\n",
              "       [ 611, 2235, 2236,   30],\n",
              "       [2235, 2236,   30, 1021]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "sequences = []\n",
        "for i in range(3, len(sequence_data)):\n",
        "\twords = sequence_data[i-3:i+1]\n",
        "\tsequences.append(words)\n",
        "print(\"The length of sequences are: \", len(sequences))\n",
        "sequences = np.array(sequences)\n",
        "sequences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9BFmPkntOl5g"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "for i in sequences:\n",
        "\tX.append(i[0:3])\n",
        "\ty.append(i[3])\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwmo-BiySzjW",
        "outputId": "767694ae-badf-455b-e470-962ec4e33c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:  [[ 145 4789    1]\n",
            " [4789    1 1020]\n",
            " [   1 1020    4]\n",
            " [1020    4  128]\n",
            " [   4  128   34]\n",
            " [ 128   34   45]\n",
            " [  34   45  611]\n",
            " [  45  611 2235]\n",
            " [ 611 2235 2236]\n",
            " [2235 2236   30]]\n",
            "Response:  [1020    4  128   34   45  611 2235 2236   30 1021]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data: \", X[:10])\n",
        "print(\"Response: \", y[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkbNgLG9S3XE",
        "outputId": "3bbcb53d-b235-4a99-a83b-ee7edde40e37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "y[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v1mcHVrnVCa9"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=3))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(vocab_size, activation=\"softmax\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGnr2yqjYIg_",
        "outputId": "744a9f40-3749-439a-fcb8-4e2ceed3eeaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 10)             89310     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8931)              8939931   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,078,241\n",
            "Trainable params: 22,078,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUQo_7ewYON1",
        "outputId": "13997684-ab2f-48cf-8f2a-e096d2c5dd7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 6.4328\n",
            "Epoch 1: loss improved from inf to 6.43284, saving model to next_words.h5\n",
            "488/488 [==============================] - 706s 1s/step - loss: 6.4328\n",
            "Epoch 2/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 6.0991\n",
            "Epoch 2: loss improved from 6.43284 to 6.09911, saving model to next_words.h5\n",
            "488/488 [==============================] - 667s 1s/step - loss: 6.0991\n",
            "Epoch 3/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 5.7491\n",
            "Epoch 3: loss improved from 6.09911 to 5.74908, saving model to next_words.h5\n",
            "488/488 [==============================] - 660s 1s/step - loss: 5.7491\n",
            "Epoch 4/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 5.4833\n",
            "Epoch 4: loss improved from 5.74908 to 5.48332, saving model to next_words.h5\n",
            "488/488 [==============================] - 660s 1s/step - loss: 5.4833\n",
            "Epoch 5/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 5.2573\n",
            "Epoch 5: loss improved from 5.48332 to 5.25725, saving model to next_words.h5\n",
            "488/488 [==============================] - 660s 1s/step - loss: 5.2573\n",
            "Epoch 6/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 5.0496\n",
            "Epoch 6: loss improved from 5.25725 to 5.04957, saving model to next_words.h5\n",
            "488/488 [==============================] - 662s 1s/step - loss: 5.0496\n",
            "Epoch 7/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 4.8549\n",
            "Epoch 7: loss improved from 5.04957 to 4.85485, saving model to next_words.h5\n",
            "488/488 [==============================] - 663s 1s/step - loss: 4.8549\n",
            "Epoch 8/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 4.6718\n",
            "Epoch 8: loss improved from 4.85485 to 4.67185, saving model to next_words.h5\n",
            "488/488 [==============================] - 660s 1s/step - loss: 4.6718\n",
            "Epoch 9/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 4.4888\n",
            "Epoch 9: loss improved from 4.67185 to 4.48879, saving model to next_words.h5\n",
            "488/488 [==============================] - 657s 1s/step - loss: 4.4888\n",
            "Epoch 10/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 4.3000\n",
            "Epoch 10: loss improved from 4.48879 to 4.30000, saving model to next_words.h5\n",
            "488/488 [==============================] - 660s 1s/step - loss: 4.3000\n",
            "Epoch 11/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 4.1076\n",
            "Epoch 11: loss improved from 4.30000 to 4.10756, saving model to next_words.h5\n",
            "488/488 [==============================] - 659s 1s/step - loss: 4.1076\n",
            "Epoch 12/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 3.9086\n",
            "Epoch 12: loss improved from 4.10756 to 3.90864, saving model to next_words.h5\n",
            "488/488 [==============================] - 662s 1s/step - loss: 3.9086\n",
            "Epoch 13/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 3.7049\n",
            "Epoch 13: loss improved from 3.90864 to 3.70492, saving model to next_words.h5\n",
            "488/488 [==============================] - 663s 1s/step - loss: 3.7049\n",
            "Epoch 14/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 3.4973\n",
            "Epoch 14: loss improved from 3.70492 to 3.49727, saving model to next_words.h5\n",
            "488/488 [==============================] - 663s 1s/step - loss: 3.4973\n",
            "Epoch 15/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 3.2832\n",
            "Epoch 15: loss improved from 3.49727 to 3.28318, saving model to next_words.h5\n",
            "488/488 [==============================] - 668s 1s/step - loss: 3.2832\n",
            "Epoch 16/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 3.0702\n",
            "Epoch 16: loss improved from 3.28318 to 3.07022, saving model to next_words.h5\n",
            "488/488 [==============================] - 666s 1s/step - loss: 3.0702\n",
            "Epoch 17/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 2.8582\n",
            "Epoch 17: loss improved from 3.07022 to 2.85821, saving model to next_words.h5\n",
            "488/488 [==============================] - 665s 1s/step - loss: 2.8582\n",
            "Epoch 18/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 2.6496\n",
            "Epoch 18: loss improved from 2.85821 to 2.64961, saving model to next_words.h5\n",
            "488/488 [==============================] - 669s 1s/step - loss: 2.6496\n",
            "Epoch 19/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 2.4497\n",
            "Epoch 19: loss improved from 2.64961 to 2.44967, saving model to next_words.h5\n",
            "488/488 [==============================] - 669s 1s/step - loss: 2.4497\n",
            "Epoch 20/20\n",
            "488/488 [==============================] - ETA: 0s - loss: 2.2513\n",
            "Epoch 20: loss improved from 2.44967 to 2.25127, saving model to next_words.h5\n",
            "488/488 [==============================] - 670s 1s/step - loss: 2.2513\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0edb08a590>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
        "model.fit(X, y, epochs=20, batch_size=228, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NpKIDLm8Z9_v"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "model = load_model('next_words.h5')\n",
        "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "\tsequence = tokenizer.texts_to_sequences([text])\n",
        "\tsequence = np.array(sequence)\n",
        "\tpreds = np.argmax(model.predict(sequence))\n",
        "\tpredicted_word = \"\"\n",
        "\t\n",
        "\tfor key, value in tokenizer.word_index.items():\n",
        "\t\tif value == preds:\n",
        "\t\t\tpredicted_word = key\n",
        "\t\t\tbreak\n",
        "\tprint(predicted_word)\n",
        "\treturn predicted_word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "krP_-cKtZ7t7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d61939c-05c6-4ae5-8c99-5fbd34c2c296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your line: with this eBook\n",
            "['with', 'this', 'eBook']\n",
            "or\n",
            "Enter your line: The Adventures of\n",
            "['The', 'Adventures', 'of']\n",
            "sherlock\n",
            "Enter your line: 0\n",
            "Execution completed.....\n"
          ]
        }
      ],
      "source": [
        "while(True):\n",
        "\ttext = input(\"Enter your line: \")\n",
        "\tif text == \"0\":\n",
        "\t\tprint(\"Execution completed.....\")\n",
        "\t\tbreak\n",
        "\telse:\n",
        "\t\ttry:\n",
        "\t\t\ttext = text.split(\" \")\n",
        "\t\t\ttext = text[-3:]\n",
        "\t\t\tprint(text)\n",
        "\t\t\tPredict_Next_Words(model, tokenizer, text)\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(\"Error occurred: \",e)\n",
        "\t\t\tcontinue"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "nwp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJvvr/FhKx/fmIHaRhTIjF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}